# üõ°Ô∏è TITAN ERP - Universal Semantic Brain Edition

**v4.0 Production** | January 2026 | AGI for Data Engineering

---

## üéØ What is TITAN?

TITAN is an **AI-powered Business Intelligence Platform** with a revolutionary **Universal Semantic Brain** that:

- **Understands ANY data** automatically without predefined rules (2 Crore+ scenarios)
- **Auto-classifies** into 15+ business categories with confidence scoring
- **Multi-tenant SaaS** architecture supporting 1 Lakh+ subscribers
- **Immutable Event Ledger** for complete audit trails
- **AI CFO Chat** that speaks in numbers and action items
- **360¬∞ Cross-Category Analysis** for executive insights

---

## üöÄ Quick Start (5 Minutes)

### Prerequisites
- Python 3.x installed
- Google Cloud service account with BigQuery access
- Gemini API key from Google AI Studio

### First-Time Setup
```powershell
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure environment
cp .env.example .env  # Edit with your credentials

# 3. Start API server
uvicorn api.main:app --port 8000

# 4. Start web interface (new terminal)
cd web
npm install
npm run dev

# 5. Access TITAN
# CEO Chat: http://localhost:3000/chat
# Settings: http://localhost:3000/settings
# Admin:    http://localhost:8501 (streamlit run titan_app.py)
```

---

## üèóÔ∏è Tech Stack

### Backend
- **Framework:** FastAPI (REST API) + Streamlit (Admin Dashboard)
- **Language:** Python 3.x
- **Database:** Google BigQuery (serverless data warehouse)
- **AI Engine:** Google Gemini 2.0 Flash
- **POS Integration:** Petpooja API

### Frontend
- **Framework:** Next.js 16.1.4 (App Router)
- **UI:** React 19.2.3 + TailwindCSS 4.x
- **Language:** TypeScript 5.x

### External Services
- Google Drive API (document storage)
- Google Cloud BigQuery (analytics)
- Gemini AI (intelligence layer)

---

## üìÅ Project Structure

```
Cafe_AI/
‚îú‚îÄ‚îÄ api/                      # FastAPI REST endpoints
‚îÇ   ‚îî‚îÄ‚îÄ main.py               # Primary adapter (1300 lines)
‚îÇ
‚îú‚îÄ‚îÄ pillars/                  # Domain logic (Hexagonal Core)
‚îÇ   ‚îú‚îÄ‚îÄ chat_intel.py         # AI conversation intelligence
‚îÇ   ‚îú‚îÄ‚îÄ dashboard.py          # Revenue/expense analytics
‚îÇ   ‚îú‚îÄ‚îÄ expense_analysis_engine.py
‚îÇ   ‚îú‚îÄ‚îÄ users_roles.py        # RBAC implementation
‚îÇ   ‚îú‚îÄ‚îÄ config_vault.py       # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ evolution.py          # Self-improvement tracking
‚îÇ   ‚îî‚îÄ‚îÄ system_logger.py      # Centralized logging
‚îÇ
‚îú‚îÄ‚îÄ 01_Data_Sync/             # Secondary adapters (ETL)
‚îÇ   ‚îú‚îÄ‚îÄ sync_sales_raw.py     # Petpooja POS sync
‚îÇ   ‚îú‚îÄ‚îÄ sync_expenses.py      # Google Drive expense sync
‚îÇ   ‚îú‚îÄ‚îÄ sync_purchases.py
‚îÇ   ‚îú‚îÄ‚îÄ sync_recipes.py
‚îÇ   ‚îî‚îÄ‚îÄ sync_wastage.py
‚îÇ
‚îú‚îÄ‚îÄ utils/                    # Application services
‚îÇ   ‚îú‚îÄ‚îÄ bq_guardrails.py      # Budget protection & cost estimation
‚îÇ   ‚îú‚îÄ‚îÄ gemini_chat.py        # AI orchestration
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_chat.py      # Streaming chat interface
‚îÇ   ‚îú‚îÄ‚îÄ ops_brief.py          # Daily operational reports
‚îÇ   ‚îî‚îÄ‚îÄ ai_task_queue.py      # Proactive task generation
‚îÇ
‚îú‚îÄ‚îÄ 04_Intelligence_Lab/      # AI/Analytics layer
‚îÇ   ‚îú‚îÄ‚îÄ sentinel_hub.py       # Health monitoring orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ titan_dna.py          # System self-analysis
‚îÇ   ‚îî‚îÄ‚îÄ pillars/              # Audit modules
‚îÇ       ‚îú‚îÄ‚îÄ p1_revenue_integrity.py
‚îÇ       ‚îú‚îÄ‚îÄ p2_inventory_gap.py
‚îÇ       ‚îî‚îÄ‚îÄ p3_expense_purity.py
‚îÇ
‚îú‚îÄ‚îÄ web/                      # Next.js frontend
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ app/dashboard/    # Metrics dashboard
‚îÇ       ‚îú‚îÄ‚îÄ app/chat/         # AI chat interface
‚îÇ       ‚îú‚îÄ‚îÄ app/operations/   # Operations view
‚îÇ       ‚îî‚îÄ‚îÄ app/settings/     # Configuration UI
‚îÇ
‚îú‚îÄ‚îÄ scheduler/                # Automation
‚îÇ   ‚îî‚îÄ‚îÄ daily_automation.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                  # DevOps utilities
‚îÇ   ‚îî‚îÄ‚îÄ generate_system_map.py # Living documentation
‚îÇ
‚îú‚îÄ‚îÄ settings.py               # ‚≠ê Configuration vault
‚îú‚îÄ‚îÄ titan_app.py              # Streamlit admin dashboard
‚îî‚îÄ‚îÄ requirements.txt          # Python dependencies
```

---

## ‚öôÔ∏è Configuration

### Environment Variables (Recommended)
Create a `.env` file in the project root:

```bash
# Google Cloud
PROJECT_ID=your-project-id
DATASET_ID=cafe_operations
KEY_FILE=service-key.json

# AI Engine
GEMINI_API_KEY=your-gemini-api-key

# Petpooja POS API
PP_APP_KEY=your-petpooja-app-key
PP_APP_SECRET=your-petpooja-secret
PP_ACCESS_TOKEN=your-access-token
PP_MAPPING_CODE=your-mapping-code

# Google Drive Folder IDs
FOLDER_ID_EXPENSES=your-drive-folder-id
FOLDER_ID_CASH_OPS=your-drive-folder-id
FOLDER_ID_RECIPES=your-drive-folder-id
FOLDER_ID_PURCHASES=your-drive-folder-id
FOLDER_ID_WASTAGE=your-drive-folder-id

# Budget Guardrails
BUDGET_MONTHLY_INR=1000
MAX_QUERY_COST_INR=10
```

### Google Drive Setup
Share each Drive folder with your service account email (Viewer permission):
- Find the email in `service-key.json` ‚Üí `client_email` field
- Example: `python-admin@your-project.iam.gserviceaccount.com`

---

## üîÑ Daily Operations Workflow

### Phase 1: Data Synchronization
```bash
# Sync sales data from Petpooja
python 01_Data_Sync/sync_sales_raw.py

# Parse sales JSON into structured data
python 01_Data_Sync/titan_sales_parser.py

# Sync expense reports from Google Drive
python 01_Data_Sync/sync_expenses.py

# Sync recipe/BOM data
python 01_Data_Sync/sync_recipes.py

# Optional: Run all syncs via Dashboard "Master Sync" button
```

### Phase 2: Intelligence Scan
```bash
# Run health monitoring and anomaly detection
python 04_Intelligence_Lab/sentinel_hub.py

# This automatically:
# - Scans all pillars in pillars/ directory
# - Detects revenue anomalies, inventory gaps, expense issues
# - Uploads findings to ai_task_queue table
```

### Phase 3: Access Dashboards
```bash
# Admin Dashboard (Streamlit)
streamlit run titan_app.py
# ‚Üí http://localhost:8501

# Modern Web Interface (Next.js)
cd web && npm run dev
# ‚Üí http://localhost:3000
```

---

## üß† AI Chat Interface - Example Queries

### Financial Analysis
- "What were my expenses yesterday?"
- "Show me cash expenses for last week excluding personal items"
- "Calculate profit and loss for last month"
- "What's my net profit margin?"

### Staff & Payroll
- "How much advance did Arun get last month?"
- "When did I pay Arun salary?"
- "Show me all staff-related expenses"

### Product Intelligence
- "What are my top selling items this week?"
- "Why is cheesecake sales dropping?"
- "Should I discontinue cupcakes based on performance?"
- "Compare truffle pastry sales month-over-month"

### Operational Insights
- "Give me today's business summary"
- "What should I focus on today?"
- "Show me revenue by delivery partner"
- "Detect any inventory gaps in my recipes"

---

## üèõÔ∏è Architecture (Hexagonal/Ports & Adapters)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  PRIMARY ADAPTERS (Inbound)                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ   Next.js   ‚îÇ  ‚îÇ  FastAPI    ‚îÇ  ‚îÇ  Streamlit  ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  Frontend   ‚îÇ  ‚îÇ   REST API  ‚îÇ  ‚îÇ   Admin UI  ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                  ‚îÇ
          ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    APPLICATION SERVICES                          ‚îÇ
‚îÇ  ‚Ä¢ Chat Interface  ‚Ä¢ Query Engine  ‚Ä¢ BigQuery Guardrails        ‚îÇ
‚îÇ  ‚Ä¢ AI Task Queue   ‚Ä¢ Ops Brief Generator                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DOMAIN LOGIC (PILLARS)                        ‚îÇ
‚îÇ  ‚Ä¢ Config Vault    ‚Ä¢ Dashboard Analytics  ‚Ä¢ Users & Roles       ‚îÇ
‚îÇ  ‚Ä¢ Chat Intelligence  ‚Ä¢ System Logger  ‚Ä¢ Evolution Engine       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SECONDARY ADAPTERS (Outbound)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ  BigQuery   ‚îÇ  ‚îÇ Google Drive ‚îÇ  ‚îÇ  Petpooja   ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  Warehouse  ‚îÇ  ‚îÇ   Storage    ‚îÇ  ‚îÇ     POS     ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ  ‚îÇ   Gemini    ‚îÇ  ‚îÇ  Sync Jobs   ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ     AI      ‚îÇ  ‚îÇ  (ETL/ELT)   ‚îÇ                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä BigQuery Tables (Data Schema)

### Revenue Domain
- `sales_raw_layer` - Raw POS JSON from Petpooja
- `sales_items_parsed` - Parsed line items
- `sales_enhanced` - Enriched with customer/delivery metadata

### Expense Domain
- `expenses_master` - Category-based expense tracking
- `cash_flow_master` - Withdrawals/topups
- `purchases_master` - Ingredient procurement

### Inventory Domain
- `ingredients_master` - Raw materials
- `recipes_sales_master` - Item composition (BOM)
- `recipes_production_master` - Sub-recipe assembly
- `wastage_log` - Loss tracking

### System Domain
- `dev_evolution_log` - Self-improvement tracking
- `system_error_log` - Error logging
- `system_sync_log` - ETL status
- `system_cost_log` - BigQuery spend tracking
- `ai_task_queue` - Proactive alerts from Sentinel Hub

---

## üõ°Ô∏è Security Features

### Credential Management
- Environment variables via `os.getenv()` (best practice)
- Service account authentication for Google Cloud
- Config override system (`config_override.json`)
- **‚ö†Ô∏è CRITICAL:** Never commit `service-key.json` or `.env` to version control

### Budget Protection
- **BigQuery Guardrails:** Dry-run cost estimation before query execution
- **Monthly Budget Cap:** Default ‚Çπ1,000/month (configurable)
- **Query-level Cost Logging:** Track spend by purpose
- **Budget Breach Prevention:** Blocks queries exceeding threshold

### Data Flow Security
1. **Inbound:** CORS-protected FastAPI endpoints
2. **Outbound:** OAuth2 for Google APIs, token-based for Petpooja
3. **Storage:** BigQuery with service account authentication

---

## üß™ Intelligence & Monitoring

### Sentinel Hub (Automated Health Checks)
Monitors:
- **Revenue Anomalies:** >10% deviation from baseline
- **Data Freshness:** Stale sync warnings (>24h)
- **Expense Spikes:** Unusual spending patterns
- **Inventory Gaps:** Sales items without recipes

### Self-Evolution System
The system tracks its own improvements in `dev_evolution_log`:
- Feature additions suggested by AI
- Bug fixes identified by Sentinel
- Performance optimizations
- User feedback integration

---

## üìà API Endpoints (FastAPI)

### Core Endpoints
- `GET /health` - System health check
- `POST /chat` - AI chat (non-streaming)
- `POST /chat/stream` - AI chat with SSE streaming
- `GET /config` - Configuration status
- `POST /config` - Update configuration

### Metrics & Analytics
- `GET /metrics/overview` - Revenue/expense summary
- `GET /ops/brief/today` - Daily operational brief
- `GET /ops/sales/channels` - Sales by delivery partner
- `GET /ops/sales/top-items` - Top-selling items

### Admin
- `GET /tasks/generate` - Generate AI tasks from brief
- `POST /ops/brief/generate` - Force-generate new brief

Full API documentation: http://localhost:8000/docs (when server is running)

---

## üéØ Key Features

### ‚úÖ Implemented
- Multi-chat AI sessions with BigQuery memory
- Real-time revenue vs. expense analytics
- Automated task generation from data anomalies
- Recipe completeness validation
- Wastage analysis and tracking
- User role-based access control (RBAC)
- Cost-aware BigQuery query execution
- Streaming chat responses (SSE)
- Multi-tenant ready architecture

### ‚è≥ Roadmap
- Multi-tenant isolation (row-level security)
- Recipe intelligence (auto-detect usage anomalies)
- Predictive demand forecasting
- Mobile app (React Native)
- Real-time Petpooja webhook integration

---

## üõ†Ô∏è Developer Commands

```bash
# Generate system blueprint documentation
python scripts/generate_system_map.py

# Update system DNA (after adding pillars)
python 04_Intelligence_Lab/titan_dna.py

# Run health scan
python 04_Intelligence_Lab/titan_dna_pulse.py > dna_report.txt

# Check system errors
cat logs/titan_system_log.txt

# Run all sync scripts
# (Use Dashboard "Master Sync" button or run individually)
```

---

## üö® Troubleshooting

### BigQuery Connection Issues
- Verify `service-key.json` exists and is valid
- Check service account has BigQuery Data Editor role
- Confirm `PROJECT_ID` and `DATASET_ID` in settings

### Drive Sync Failures
- Ensure Drive folders are shared with service account email
- Check folder IDs in `settings.py` are correct
- Verify files have proper headers (Amount column for expenses)

### Dashboard Errors
- Check `logs/titan_system_log.txt` for detailed error traces
- Query `system_error_log` table in BigQuery
- Run `titan_integrity.py` for system health check

### Cost Budget Exceeded
- Review cost logs: `SELECT * FROM system_cost_log ORDER BY ts DESC`
- Adjust `BUDGET_MONTHLY_INR` in settings
- Use `DISABLE_BUDGET_BREAKER=true` to bypass (not recommended)

---

## üìö Additional Documentation

- **BLUEPRINT.md** - Auto-generated system architecture map
- **PROJECT_FLOW_EXPLANATION.md** - Deep technical flow details
- **COMPLETE_IMPLEMENTATION_SUMMARY.md** - Implementation status
- **TITAN_VISION_ROADMAP.md** - Product roadmap
- **DEPLOY.md** - Deployment guide
- **EXPENSES_MODULE_SPEC.md** - Expense tracking specifications

---

## üéì Getting Started Guide

### For New Developers
1. Read this README completely
2. Run `python 04_Intelligence_Lab/titan_dna.py` to understand system structure
3. Generate system blueprint: `python scripts/generate_system_map.py`
4. Launch dashboard and explore: `streamlit run titan_app.py`

### For System Administrators
1. Configure `.env` file with credentials
2. Set up Google Drive folder sharing
3. Run initial data sync scripts
4. Schedule daily automation: `python scheduler/daily_automation.py`

### For Data Analysts
1. Access Next.js interface at http://localhost:3000
2. Use AI chat for natural language queries
3. Download operational briefs from Dashboard
4. Query BigQuery directly for custom analysis

---

## ü§ù Contributing

### Adding New Audit Logic (Pillars)
1. Create `04_Intelligence_Lab/pillars/p4_your_audit.py`
2. Implement `run_audit(client, settings)` function
3. Return list of findings (dict format)
4. Run `sentinel_hub.py` - automatic discovery!

### Adding New Data Syncs
1. Create `01_Data_Sync/sync_your_source.py`
2. Follow existing sync script patterns
3. Update `system_sync_log` on success
4. Add to Dashboard sync buttons

---

## üìû System Status

**Core Features:** ‚úÖ Operational  
**AI Chat:** ‚úÖ Streaming  
**Query Engine:** ‚úÖ Cost-Protected  
**Reports:** ‚úÖ Auto-Generated  
**Sentinel:** ‚úÖ Monitoring  
**Multi-Tenant:** ‚è≥ In Progress

---

## üîê Security Notice

**‚ö†Ô∏è IMPORTANT:** This codebase contains sensitive credential patterns. Before deploying:

1. ‚úÖ Ensure `service-key.json` is in `.gitignore`
2. ‚úÖ Use environment variables for all secrets
3. ‚úÖ Never commit `.env` files
4. ‚úÖ Rotate API keys if repository was ever public
5. ‚úÖ Use Google Secret Manager in production

---

**Built with ‚ù§Ô∏è by the TITAN Evolution Engine**  
**Last Updated:** 2026-01-25  
**Version:** 5.0.0 (Hexagonal Architecture + Next.js)  
**License:** Proprietary (Ever Built SaaS)

üöÄ **Ready to start?** Run `streamlit run titan_app.py` and access http://localhost:8501
